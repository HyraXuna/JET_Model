import streamlit as st
import matplotlib.pyplot as plt
import os
import json
import tensorflow as tf

st.title("Pr√©sentation et informations sur la baseline, le 1er mod√®le utilis√©, le plus simple mais correct ü§ñ")
           
history_path = tf.keras.utils.get_file(
    "inceptionV3modelHistory.json",
    origin="https://huggingface.co/HyraXuna/JET_model_inceptionV3_base/resolve/main/inceptionV3modelHistory.json",
    cache_subdir='models'
    )

if not os.path.exists(history_path):
    st.error("L'historique du mod√®le n'a pas pu √™tre t√©l√©charg√©.")

with open(history_path, "r") as f:
    metrics = json.load(f)



st.markdown("""
            Pour commencer, le mod√®le initial est le plus simpliste qui nous a donn√© des r√©sultats corrects. 
            C'est un mod√®le de deep learning utilisant du transfer learning, c'est √† dire que l'architecture est bas√©e sur un mod√®le pr√©entrain√©.
            Dans notre cas, il se base sur **InceptionV3**, pr√©entrain√© avec les images de *imagenet*.
""")

st.markdown("""
            Ce mod√®le est stock√© √† cette adresse : https://huggingface.co/HyraXuna/JET_model_inceptionV3_base/tree/main

            Si vous d√©sirez le t√©l√©charger, veuillez cliquez ici : [t√©l√©charger le mod√®le ü¶ä](https://huggingface.co/HyraXuna/JET_model_inceptionV3_base/resolve/main/inceptionV3model.h5)
""")

st.subheader("Sch√©ma du mod√®le ü™™")

# Affichage du sch√©ma de structure en HTML
st.markdown("""
<table style="width:100%; border-collapse: collapse;">
  <tr style="border: 1px solid white;">
    <th style="border: 1px solid white; padding: 8px; text-align: left;"><b>Layer (type)</b></th>
    <th style="border: 1px solid white; padding: 8px; text-align: left;"><b>Output Shape</b></th>
    <th style="border: 1px solid white; padding: 8px; text-align: left;"><b>Param #</b></th>
  </tr>
  <tr style="border: 1px solid white;">
    <td style="border: 1px solid white; padding: 8px;">inception_v3 (<span style="color: #0087ff;">Functional</span>)</td>
    <td style="border: 1px solid white; padding: 8px;">(<span style="color: #00d7ff;">None</span>, <span style="color: #00af00;">5</span>, <span style="color: #00af00;">5</span>, <span style="color: #00af00;">2048</span>)</td>
    <td style="border: 1px solid white; padding: 8px;"><span style="color: #00af00;">21,802,784</span></td>
  </tr>
  <tr style="border: 1px solid white;">
    <td style="border: 1px solid white; padding: 8px;">global_average_pooling2d_2 (<span style="color: #0087ff;">GlobalAveragePooling2D</span>)</td>
    <td style="border: 1px solid white; padding: 8px;">(<span style="color: #00d7ff;">None</span>, <span style="color: #00af00;">2048</span>)</td>
    <td style="border: 1px solid white; padding: 8px;"><span style="color: #00af00;">0</span></td>
  </tr>
  <tr style="border: 1px solid white;">
    <td style="border: 1px solid white; padding: 8px;">dense_6 (<span style="color: #0087ff;">Dense</span>)</td>
    <td style="border: 1px solid white; padding: 8px;">(<span style="color: #00d7ff;">None</span>, <span style="color: #00af00;">256</span>)</td>
    <td style="border: 1px solid white; padding: 8px;"><span style="color: #00af00;">524,544</span></td>
  </tr>
  <tr style="border: 1px solid white;">
    <td style="border: 1px solid white; padding: 8px;">dense_7 (<span style="color: #0087ff;">Dense</span>)</td>
    <td style="border: 1px solid white; padding: 8px;">(<span style="color: #00d7ff;">None</span>, <span style="color: #00af00;">128</span>)</td>
    <td style="border: 1px solid white; padding: 8px;"><span style="color: #00af00;">32,896</span></td>
  </tr>
  <tr style="border: 1px solid white;">
    <td style="border: 1px solid white; padding: 8px;">dropout_2 (<span style="color: #0087ff;">Dropout</span>)</td>
    <td style="border: 1px solid white; padding: 8px;">(<span style="color: #00d7ff;">None</span>, <span style="color: #00af00;">128</span>)</td>
    <td style="border: 1px solid white; padding: 8px;"><span style="color: #00af00;">0</span></td>
  </tr>
  <tr style="border: 1px solid white;">
    <td style="border: 1px solid white; padding: 8px;">dense_8 (<span style="color: #0087ff;">Dense</span>)</td>
    <td style="border: 1px solid white; padding: 8px;">(<span style="color: #00d7ff;">None</span>, <span style="color: #00af00;">1</span>)</td>
    <td style="border: 1px solid white; padding: 8px;"><span style="color: #00af00;">129</span></td>
  </tr>
</table>
            
Total params: <span style="color: #00af00;">22,360,353</span> (85.30 MB)
            

Trainable params: <span style="color: #00af00;">557,569</span> (2.13 MB)
            

Non-trainable params: <span style="color: #00af00;">21,802,784</span> (83.17 MB)
            
""", unsafe_allow_html=True)

st.markdown("""
            Le mod√®le a √©t√© entrain√© avec l'optimizer `Adam` avec un learning rate de $1^{-5}$, 
            ainsi qu'un calcul de fonction de co√ªt et des m√©triques pour une classification binaire 
            (`BinaryCrossentropy` & `BinaryAccuracy`).
""")


st.subheader("Performances du mod√®le üìà")

col1, col2 = st.columns(2)

with col1:

    # Visualise train / Valid Accuracy
    plt.figure(figsize=(10, 6))
    plt.plot(metrics["binary_accuracy"], c="r", label="train_accuracy")
    plt.plot(metrics["val_binary_accuracy"], c="b", label="test_accuracy")
    plt.title("Accuracy of the model, Train Vs Validation")
    plt.legend()
    plt.xlabel("Epochs")
    plt.ylabel("Accuracy")

     # Afficher le graphique dans Streamlit
    st.pyplot(plt)

with col2:

    # Visualise train / Valid Accuracy
    plt.figure(figsize=(10, 6))
    plt.plot(metrics["loss"], c="r", label="train_loss")
    plt.plot(metrics["val_loss"], c="b", label="test_loss")
    plt.title("Loss of the model, Train Vs Validation")
    plt.legend()
    plt.xlabel("Epochs")
    plt.ylabel("Loss")

     # Afficher le graphique dans Streamlit
    st.pyplot(plt)

st.write("")
st.markdown("""
            Et maintenant voici la matrice de confusion correspondant √† ce mod√®le, avec les donn√©es de validations:
""")


col1, col2, col3 = st.columns([1, 2, 1])

# Utiliser la colonne centrale pour afficher l'image
with col2:
    st.image("pages/confusion_matrix/matrix_confusion_inceptionv3.png", use_container_width=True)


st.title("Pr√©sentation et informations sur le mod√®le final ü§ñ")

history_path2 = tf.keras.utils.get_file(
    "mobilenetv2_fine_tune_History.json",
    origin="https://huggingface.co/HyraXuna/Jet_model_MobileNetV2/resolve/main/mobilenetv2model_finetune_History.json",
    cache_subdir='models'
    )

if not os.path.exists(history_path2):
    st.error("L'historique du mod√®le n'a pas pu √™tre t√©l√©charg√©.")

with open(history_path2, "r") as f:
    metrics2 = json.load(f)

st.markdown("""
            Ce mod√®le plus performant, donnant de meilleurs r√©sultats, utilise aussi du transfer learning, mais cette fois-ci bas√© sur 
            le mod√®le **MobileNetV2** pr√©entrain√© avec les images de *imagenet*. 
            Du fine tuning a √©t√© effectu√© ici pour am√©liorer les performance et permettre un apprentissage plus pouss√© sur nos donn√©es.

            Le mod√®le a √©t√© sauvegard√© √† chaque epoch o√π son score progressait. Donc pour la pr√©diction, nous avons utilis√© celui sauvegard√©
            √† l'epoch 23 avec un score de validation de 0.8622.
            """)

st.markdown("""
            Ce mod√®le est stock√© √† cette adresse : https://huggingface.co/HyraXuna/Jet_model_MobileNetV2/tree/main

            Si vous d√©sirez t√©l√©charger le mod√®le entier, √† la fin des epoch, veuillez cliquez ici : [t√©l√©charger le mod√®le √† la derni√®re epoch ü¶ä](https://huggingface.co/HyraXuna/Jet_model_MobileNetV2/resolve/main/mobilenetv2model_finetune.h5)

            Si vous d√©sirez t√©l√©charger le mod√®le au meilleur checkpoint, √† l'epoch 23, veuillez cliquez ici : [t√©l√©charger le mod√®le √† la meilleure epoch üêØ](https://huggingface.co/HyraXuna/Jet_model_MobileNetV2/resolve/main/model_epoch_23_val_acc_0.86.h5)
""")

st.subheader("Sch√©ma du mod√®le ü™™")

# Affichage du sch√©ma de structure en HTML
st.markdown("""
<table style="width:100%; border-collapse: collapse;">
  <tr style="border: 1px solid white;">
    <th style="border: 1px solid white; padding: 8px; text-align: left;"><b>Layer (type)</b></th>
    <th style="border: 1px solid white; padding: 8px; text-align: left;"><b>Output Shape</b></th>
    <th style="border: 1px solid white; padding: 8px; text-align: left;"><b>Param #</b></th>
  </tr>
  <tr style="border: 1px solid white;">
    <td style="border: 1px solid white; padding: 8px;">mobilenetv2_1.00_224 (<span style="color: #0087ff;">Functional</span>)</td>
    <td style="border: 1px solid white; padding: 8px;">(<span style="color: #00d7ff;">None</span>, <span style="color: #00af00;">7</span>, <span style="color: #00af00;">7</span>, <span style="color: #00af00;">1280</span>)</td>
    <td style="border: 1px solid white; padding: 8px;"><span style="color: #00af00;">2,257,984</span></td>
  </tr>
  <tr style="border: 1px solid white;">
    <td style="border: 1px solid white; padding: 8px;">global_average_pooling2d (<span style="color: #0087ff;">GlobalAveragePooling2D</span>)</td>
    <td style="border: 1px solid white; padding: 8px;">(<span style="color: #00d7ff;">None</span>, <span style="color: #00af00;">1280</span>)</td>
    <td style="border: 1px solid white; padding: 8px;"><span style="color: #00af00;">0</span></td>
  </tr>
  <tr style="border: 1px solid white;">
    <td style="border: 1px solid white; padding: 8px;">dense (<span style="color: #0087ff;">Dense</span>)</td>
    <td style="border: 1px solid white; padding: 8px;">(<span style="color: #00d7ff;">None</span>, <span style="color: #00af00;">256</span>)</td>
    <td style="border: 1px solid white; padding: 8px;"><span style="color: #00af00;">327,936</span></td>
  </tr>
  <tr style="border: 1px solid white;">
    <td style="border: 1px solid white; padding: 8px;">dense_1 (<span style="color: #0087ff;">Dense</span>)</td>
    <td style="border: 1px solid white; padding: 8px;">(<span style="color: #00d7ff;">None</span>, <span style="color: #00af00;">128</span>)</td>
    <td style="border: 1px solid white; padding: 8px;"><span style="color: #00af00;">32,896</span></td>
  </tr>
  <tr style="border: 1px solid white;">
    <td style="border: 1px solid white; padding: 8px;">dropout (<span style="color: #0087ff;">Dropout</span>)</td>
    <td style="border: 1px solid white; padding: 8px;">(<span style="color: #00d7ff;">None</span>, <span style="color: #00af00;">128</span>)</td>
    <td style="border: 1px solid white; padding: 8px;"><span style="color: #00af00;">0</span></td>
  </tr>
  <tr style="border: 1px solid white;">
    <td style="border: 1px solid white; padding: 8px;">dense_2 (<span style="color: #0087ff;">Dense</span>)</td>
    <td style="border: 1px solid white; padding: 8px;">(<span style="color: #00d7ff;">None</span>, <span style="color: #00af00;">1</span>)</td>
    <td style="border: 1px solid white; padding: 8px;"><span style="color: #00af00;">129</span></td>
  </tr>
</table>

<br/>

<b>Total params:</b> <span style="color: #00af00;">2,618,945</span> (9.99 MB)  
<br/>
<b>Trainable params:</b> <span style="color: #00af00;">1,093,441</span> (4.17 MB)  
<br/>
<b>Non-trainable params:</b> <span style="color: #00af00;">1,525,504</span> (5.82 MB)
""", unsafe_allow_html=True)



st.markdown("""
            Le mod√®le a √©t√© entrain√© avec l'optimizer `Adam` avec un learning rate de $1^{-5}$, 
            ainsi qu'un calcul de fonction de co√ªt et des m√©triques pour une classification binaire 
            (`BinaryCrossentropy` & `BinaryAccuracy`). Il y avait aussi un `early stopping` bas√© sur la fonction de co√ªt de la validation
            qui arr√™tait l'entrainement du mod√®le s'il n'y avait pas de progression sur 5 epoch.
            Pour le `Fine tuning` nous avons lib√©r√© les 10 derni√®res couches du MibileNetV2.
""")


st.subheader("Performances du mod√®le üìà")

col1, col2 = st.columns(2)

with col1:

    # Visualise train / Valid Accuracy
    plt.figure(figsize=(10, 6))
    plt.plot(metrics2["binary_accuracy"], c="r", label="train_accuracy")
    plt.plot(metrics2["val_binary_accuracy"], c="b", label="test_accuracy")
    plt.title("Accuracy of the model, Train Vs Validation")
    plt.legend()
    plt.xlabel("Epochs")
    plt.ylabel("Accuracy")

     # Afficher le graphique dans Streamlit
    st.pyplot(plt)

with col2:

    # Visualise train / Valid loss
    plt.figure(figsize=(10, 6))
    plt.plot(metrics2["loss"], c="r", label="train_loss")
    plt.plot(metrics2["val_loss"], c="b", label="test_loss")
    plt.title("Loss of the model, Train Vs Validation")
    plt.legend()
    plt.xlabel("Epochs")
    plt.ylabel("Loss")

     # Afficher le graphique dans Streamlit
    st.pyplot(plt)

st.write("")
st.markdown("""
            Et maintenant voici la matrice de confusion correspondant √† ce mod√®le, avec les donn√©es de validations:
""")

col1, col2, col3 = st.columns([1, 2, 1])

# Utiliser la colonne centrale pour afficher l'image
with col2:
    st.image("pages/confusion_matrix/matrix_confusion_mobilinetv2_finetune.png", use_container_width=True)
    st.write("On voit bien une am√©lioration dans la pr√©diction par rapport √† la baseline ! ‚úÖ")

st.title("Mod√®le de d√©tection : YOLOv8")

st.markdown("""
Le mod√®le YOLOv8 est un mod√®le de d√©tection d'objets d√©velopp√© par Ultralytics, qui nous a permis d‚Äôidentifier automatiquement les pneus pr√©sents dans une image et de les encadrer √† l‚Äôaide de bounding boxes. Il a √©t√© entra√Æn√© √† l‚Äôaide d‚Äôun dataset pr√©par√© avec Roboflow, contenant des images et leurs annotations au format YOLOv8 (.txt), afin de permettre la localisation des zones √† analyser.
""")

st.subheader("D√©tails techniques")

st.markdown("""
| Param√®tres            | Valeurs                                                |
|----------------------|--------------------------------------------------------|
| **Mod√®le**           | YOLOv8 (Medium)                                        |
| **Taille des images**| 800 √ó 800                                              |
| **Nbre d'EPOCH**     | 50                                                     |
|**Poids utilis√©s**    | [best.pt](https://huggingface.co/flodussart/jet_yolov8m/resolve/main/best.pt)          |
| **Fichier config**   | [data.yaml](https://huggingface.co/datasets/flodussart/tires_project_roboflow/blob/main/data.yaml) |
| **Nombre de classes**| 1 (pneu uniquement)                                    |
""", unsafe_allow_html=True)

st.subheader("Performances du mod√®le üìà")

st.markdown("""
Les m√©triques sont calcul√©es √† la fois sur l‚Äôensemble de **validation** et de **test** :

|                  | Validation | Test      |
|------------------|------------|-----------|
| üéØ **Pr√©cision**     | 93.32 %    | 96.85 %   |
| üìå **Recall**        | 93.66 %    | 91.56 %   |
| üì¶ **mAP@50**        | 97.37 %    | 97.30 %   |
| üîç **mAP@50-95**     | 61.99 %    | 61.65 %   |
""", unsafe_allow_html=True)

st.markdown("""
üëâ La pr√©cision du mod√®le est excellente, notamment en mAP@50, ce qui montre une bonne **capacit√© de d√©tection des pneus** dans diverses situations.
""")

st.markdown("---")
st.subheader("√âtapes post-d√©tection avec OpenCV (cv2)")

st.markdown("""
Apr√®s la d√©tection des pneus avec le mod√®le YOLOv8, nous utilisons la biblioth√®que **OpenCV (`cv2`)** pour effectuer plusieurs traitements essentiels :

- üìê **Redimensionnement des zones d√©tect√©es** pour les adapter √† l'entr√©e du mod√®le de classification.
- üé® **Conversion des couleurs** pour passer du format BGR (utilis√© par OpenCV) au format RGB (utilis√© par Keras et PIL).
- üß© **D√©coupage en grille (4√ó4)** de chaque pneu pour une analyse locale par zones.

Cela permet une **analyse visuelle pr√©cise et localis√©e**, utile pour d√©tecter des zones anormales m√™me sur un pneu globalement en bon √©tat.
""")


