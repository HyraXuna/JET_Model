import streamlit as st
import matplotlib.pyplot as plt
import os
import json
import tensorflow as tf

st.title("Pr√©sentation et informations sur la baseline, le 1er mod√®le utilis√©, le plus simple mais correct ü§ñ")
           
history_path = tf.keras.utils.get_file(
    "inceptionV3modelHistory.json",
    origin="https://huggingface.co/HyraXuna/JET_model_inceptionV3_base/resolve/main/inceptionV3modelHistory.json",
    cache_subdir='models'
    )

if not os.path.exists(history_path):
    st.error("L'historique du mod√®le n'a pas pu √™tre t√©l√©charg√©.")

with open(history_path, "r") as f:
    metrics = json.load(f)



st.markdown("""
            Pour commencer, le mod√®le initial est le plus simpliste qui nous a donn√© des r√©sultats corrects. 
            C'est un mod√®le de deep learning utilisant du transfer learning, c'est √† dire que l'architecture est bas√©e sur un mod√®le pr√©entrain√©.
            Dans notre cas, il se base sur **InceptionV3**, pr√©entrain√© avec les images de *imagenet*.
""")

st.markdown("""
            Ce mod√®le est stock√© √† cette adresse : https://huggingface.co/HyraXuna/JET_model_inceptionV3_base/tree/main

            Si vous d√©sirez le t√©l√©charger, veuillez cliquez ici : [t√©l√©charger le mod√®le ü¶ä](https://huggingface.co/HyraXuna/JET_model_inceptionV3_base/resolve/main/inceptionV3model.h5)
""")

st.subheader("Sch√©ma du mod√®le ü™™")

# Affichage du sch√©ma de structure en HTML
st.markdown("""
<table style="width:100%; border-collapse: collapse;">
  <tr style="border: 1px solid white;">
    <th style="border: 1px solid white; padding: 8px; text-align: left;"><b>Layer (type)</b></th>
    <th style="border: 1px solid white; padding: 8px; text-align: left;"><b>Output Shape</b></th>
    <th style="border: 1px solid white; padding: 8px; text-align: left;"><b>Param #</b></th>
  </tr>
  <tr style="border: 1px solid white;">
    <td style="border: 1px solid white; padding: 8px;">inception_v3 (<span style="color: #0087ff;">Functional</span>)</td>
    <td style="border: 1px solid white; padding: 8px;">(<span style="color: #00d7ff;">None</span>, <span style="color: #00af00;">5</span>, <span style="color: #00af00;">5</span>, <span style="color: #00af00;">2048</span>)</td>
    <td style="border: 1px solid white; padding: 8px;"><span style="color: #00af00;">21,802,784</span></td>
  </tr>
  <tr style="border: 1px solid white;">
    <td style="border: 1px solid white; padding: 8px;">global_average_pooling2d_2 (<span style="color: #0087ff;">GlobalAveragePooling2D</span>)</td>
    <td style="border: 1px solid white; padding: 8px;">(<span style="color: #00d7ff;">None</span>, <span style="color: #00af00;">2048</span>)</td>
    <td style="border: 1px solid white; padding: 8px;"><span style="color: #00af00;">0</span></td>
  </tr>
  <tr style="border: 1px solid white;">
    <td style="border: 1px solid white; padding: 8px;">dense_6 (<span style="color: #0087ff;">Dense</span>)</td>
    <td style="border: 1px solid white; padding: 8px;">(<span style="color: #00d7ff;">None</span>, <span style="color: #00af00;">256</span>)</td>
    <td style="border: 1px solid white; padding: 8px;"><span style="color: #00af00;">524,544</span></td>
  </tr>
  <tr style="border: 1px solid white;">
    <td style="border: 1px solid white; padding: 8px;">dense_7 (<span style="color: #0087ff;">Dense</span>)</td>
    <td style="border: 1px solid white; padding: 8px;">(<span style="color: #00d7ff;">None</span>, <span style="color: #00af00;">128</span>)</td>
    <td style="border: 1px solid white; padding: 8px;"><span style="color: #00af00;">32,896</span></td>
  </tr>
  <tr style="border: 1px solid white;">
    <td style="border: 1px solid white; padding: 8px;">dropout_2 (<span style="color: #0087ff;">Dropout</span>)</td>
    <td style="border: 1px solid white; padding: 8px;">(<span style="color: #00d7ff;">None</span>, <span style="color: #00af00;">128</span>)</td>
    <td style="border: 1px solid white; padding: 8px;"><span style="color: #00af00;">0</span></td>
  </tr>
  <tr style="border: 1px solid white;">
    <td style="border: 1px solid white; padding: 8px;">dense_8 (<span style="color: #0087ff;">Dense</span>)</td>
    <td style="border: 1px solid white; padding: 8px;">(<span style="color: #00d7ff;">None</span>, <span style="color: #00af00;">1</span>)</td>
    <td style="border: 1px solid white; padding: 8px;"><span style="color: #00af00;">129</span></td>
  </tr>
</table>
            
Total params: <span style="color: #00af00;">22,360,353</span> (85.30 MB)
            

Trainable params: <span style="color: #00af00;">557,569</span> (2.13 MB)
            

Non-trainable params: <span style="color: #00af00;">21,802,784</span> (83.17 MB)
            
""", unsafe_allow_html=True)

st.markdown("""
            Le mod√®le a √©t√© entrain√© avec l'optimizer `Adam` avec un learning rate de $1^{-5}$, 
            ainsi qu'un calcul de fonction de co√ªt et des m√©triques pour une classification binaire 
            (`BinaryCrossentropy` & `BinaryAccuracy`).
""")


st.subheader("Performances du mod√®le üìà")

col1, col2 = st.columns(2)

with col1:

    # Visualise train / Valid Accuracy
    plt.figure(figsize=(10, 6))
    plt.plot(metrics["binary_accuracy"], c="r", label="train_accuracy")
    plt.plot(metrics["val_binary_accuracy"], c="b", label="test_accuracy")
    plt.title("Accuracy of the model, Train Vs Validation")
    plt.legend()
    plt.xlabel("Epochs")
    plt.ylabel("Accuracy")

     # Afficher le graphique dans Streamlit
    st.pyplot(plt)

with col2:

    # Visualise train / Valid Accuracy
    plt.figure(figsize=(10, 6))
    plt.plot(metrics["loss"], c="r", label="train_loss")
    plt.plot(metrics["val_loss"], c="b", label="test_loss")
    plt.title("Loss of the model, Train Vs Validation")
    plt.legend()
    plt.xlabel("Epochs")
    plt.ylabel("Loss")

     # Afficher le graphique dans Streamlit
    st.pyplot(plt)

st.write("")
st.markdown("""
            Et maintenant voici la matrice de confusion correspondant √† ce mod√®le, avec les donn√©es de validations:
""")


col1, col2, col3 = st.columns([1, 2, 1])

# Utiliser la colonne centrale pour afficher l'image
with col2:
    st.image("pages/confusion_matrix/matrix_confusion_inceptionv3.png", use_container_width=True)


st.title("Pr√©sentation et informations sur le mod√®le final ü§ñ")

history_path2 = tf.keras.utils.get_file(
    "mobilenetv2_fine_tune_History.json",
    origin="https://huggingface.co/HyraXuna/Jet_model_MobileNetV2/resolve/main/mobilenetv2model_finetune_History.json",
    cache_subdir='models'
    )

if not os.path.exists(history_path2):
    st.error("L'historique du mod√®le n'a pas pu √™tre t√©l√©charg√©.")

with open(history_path2, "r") as f:
    metrics2 = json.load(f)

st.markdown("""
            Ce mod√®le plus performant, donnant de meilleurs r√©sultats, utilise aussi du transfer learning, mais cette fois-ci bas√© sur 
            le mod√®le **MobileNetV2** pr√©entrain√© avec les images de *imagenet*. 
            Du fine tuning a √©t√© effectu√© ici pour am√©liorer les performance et permettre un apprentissage plus pouss√© sur nos donn√©es.

            Le mod√®le a √©t√© sauvegard√© √† chaque epoch o√π son score progressait. Donc pour la pr√©diction, nous avons utilis√© celui sauvegard√©
            √† l'epoch 23 avec un score de validation de 0.8622.
            """)

st.markdown("""
            Ce mod√®le est stock√© √† cette adresse : https://huggingface.co/HyraXuna/Jet_model_MobileNetV2/tree/main

            Si vous d√©sirez le t√©l√©charger le mod√®le entier, √† la fin des epoch, veuillez cliquez ici : [t√©l√©charger le mod√®le √† la derni√®re epoch ü¶ä](https://huggingface.co/HyraXuna/Jet_model_MobileNetV2/resolve/main/mobilenetv2model_finetune.h5)

            i vous d√©sirez le t√©l√©charger le mod√®le au meilleur checkpoint, √† l'epoch 23, veuillez cliquez ici : [t√©l√©charger le mod√®le √† la meilleure epoch üêØ](https://huggingface.co/HyraXuna/Jet_model_MobileNetV2/resolve/main/model_epoch_23_val_acc_0.86.h5)
""")

st.subheader("Sch√©ma du mod√®le ü™™")

# Affichage du sch√©ma de structure en HTML
st.markdown("""
<table style="width:100%; border-collapse: collapse;">
  <tr style="border: 1px solid white;">
    <th style="border: 1px solid white; padding: 8px; text-align: left;"><b>Layer (type)</b></th>
    <th style="border: 1px solid white; padding: 8px; text-align: left;"><b>Output Shape</b></th>
    <th style="border: 1px solid white; padding: 8px; text-align: left;"><b>Param #</b></th>
  </tr>
  <tr style="border: 1px solid white;">
    <td style="border: 1px solid white; padding: 8px;">mobilenetv2_1.00_224 (<span style="color: #0087ff;">Functional</span>)</td>
    <td style="border: 1px solid white; padding: 8px;">(<span style="color: #00d7ff;">None</span>, <span style="color: #00af00;">7</span>, <span style="color: #00af00;">7</span>, <span style="color: #00af00;">1280</span>)</td>
    <td style="border: 1px solid white; padding: 8px;"><span style="color: #00af00;">2,257,984</span></td>
  </tr>
  <tr style="border: 1px solid white;">
    <td style="border: 1px solid white; padding: 8px;">global_average_pooling2d (<span style="color: #0087ff;">GlobalAveragePooling2D</span>)</td>
    <td style="border: 1px solid white; padding: 8px;">(<span style="color: #00d7ff;">None</span>, <span style="color: #00af00;">1280</span>)</td>
    <td style="border: 1px solid white; padding: 8px;"><span style="color: #00af00;">0</span></td>
  </tr>
  <tr style="border: 1px solid white;">
    <td style="border: 1px solid white; padding: 8px;">dense (<span style="color: #0087ff;">Dense</span>)</td>
    <td style="border: 1px solid white; padding: 8px;">(<span style="color: #00d7ff;">None</span>, <span style="color: #00af00;">256</span>)</td>
    <td style="border: 1px solid white; padding: 8px;"><span style="color: #00af00;">327,936</span></td>
  </tr>
  <tr style="border: 1px solid white;">
    <td style="border: 1px solid white; padding: 8px;">dense_1 (<span style="color: #0087ff;">Dense</span>)</td>
    <td style="border: 1px solid white; padding: 8px;">(<span style="color: #00d7ff;">None</span>, <span style="color: #00af00;">128</span>)</td>
    <td style="border: 1px solid white; padding: 8px;"><span style="color: #00af00;">32,896</span></td>
  </tr>
  <tr style="border: 1px solid white;">
    <td style="border: 1px solid white; padding: 8px;">dropout (<span style="color: #0087ff;">Dropout</span>)</td>
    <td style="border: 1px solid white; padding: 8px;">(<span style="color: #00d7ff;">None</span>, <span style="color: #00af00;">128</span>)</td>
    <td style="border: 1px solid white; padding: 8px;"><span style="color: #00af00;">0</span></td>
  </tr>
  <tr style="border: 1px solid white;">
    <td style="border: 1px solid white; padding: 8px;">dense_2 (<span style="color: #0087ff;">Dense</span>)</td>
    <td style="border: 1px solid white; padding: 8px;">(<span style="color: #00d7ff;">None</span>, <span style="color: #00af00;">1</span>)</td>
    <td style="border: 1px solid white; padding: 8px;"><span style="color: #00af00;">129</span></td>
  </tr>
</table>

<br/>

<b>Total params:</b> <span style="color: #00af00;">2,618,945</span> (9.99 MB)  
<br/>
<b>Trainable params:</b> <span style="color: #00af00;">1,093,441</span> (4.17 MB)  
<br/>
<b>Non-trainable params:</b> <span style="color: #00af00;">1,525,504</span> (5.82 MB)
""", unsafe_allow_html=True)



st.markdown("""
            Le mod√®le a √©t√© entrain√© avec l'optimizer `Adam` avec un learning rate de $1^{-5}$, 
            ainsi qu'un calcul de fonction de co√ªt et des m√©triques pour une classification binaire 
            (`BinaryCrossentropy` & `BinaryAccuracy`). Il y avait aussi un `early stopping` bas√© sur la fonction de co√ªt de la validation
            qui arr√™tait l'entrainement du mod√®le s'il n"y avait pas de progression sur 5 epoch.
            Pour le `Fine tuning` nous avons lib√©rer les 10 derni√®res couches du MibileNetV2.
""")


st.subheader("Performances du mod√®le üìà")

col1, col2 = st.columns(2)

with col1:

    # Visualise train / Valid Accuracy
    plt.figure(figsize=(10, 6))
    plt.plot(metrics2["binary_accuracy"], c="r", label="train_accuracy")
    plt.plot(metrics2["val_binary_accuracy"], c="b", label="test_accuracy")
    plt.title("Accuracy of the model, Train Vs Validation")
    plt.legend()
    plt.xlabel("Epochs")
    plt.ylabel("Accuracy")

     # Afficher le graphique dans Streamlit
    st.pyplot(plt)

with col2:

    # Visualise train / Valid loss
    plt.figure(figsize=(10, 6))
    plt.plot(metrics2["loss"], c="r", label="train_loss")
    plt.plot(metrics2["val_loss"], c="b", label="test_loss")
    plt.title("Loss of the model, Train Vs Validation")
    plt.legend()
    plt.xlabel("Epochs")
    plt.ylabel("Loss")

     # Afficher le graphique dans Streamlit
    st.pyplot(plt)

st.write("")
st.markdown("""
            Et maintenant voici la matrice de confusion correspondant √† ce mod√®le, avec les donn√©es de validations:
""")

col1, col2, col3 = st.columns([1, 2, 1])

# Utiliser la colonne centrale pour afficher l'image
with col2:
    st.image("pages/confusion_matrix/matrix_confusion_mobilinetv2_finetune.png", use_container_width=True)
    st.write("On voit bien une am√©lioration dans la pr√©diction par rapport √† la baseline ! ‚úÖ")

